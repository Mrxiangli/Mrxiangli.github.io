---
permalink: /blog/
---

<head>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
</head>

<div class="research-container">
  
<a href="/blog/llm-inference-basic" class="research-link">
  <div class="research-topic">
    <h2>
      Large Language Model Inference
    </h2>   
    <div class="research-date">April 23rd 2025</div>
    <p>Serving large language model (LLM) can be costly due to the infrastructure involved. To reduce the operational cost, serveral efficient language model have been proposed. In this post, we cover the basic of LLM serving and some recent works in this field. </p>
  </div>
</a>

</div>